{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c84eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898ad08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric utilities loaded.\n"
     ]
    }
   ],
   "source": [
    "# Token-level IoU metric utilities\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "def char_span_to_token_span(tokenizer, context: str, answer_start: int, answer_text: str) -> Optional[Tuple[int,int]]:\n",
    "    \"\"\"Convert a character-level span to token span (start, end_exclusive).\n",
    "\n",
    "    tokenizer: a HuggingFace tokenizer configured to return offset_mapping.\n",
    "    Returns None if mapping fails.\n",
    "    \"\"\"\n",
    "    enc = tokenizer(context, add_special_tokens=False, return_offsets_mapping=True)\n",
    "    offsets = enc.get(\"offset_mapping\", [])\n",
    "    start_char = int(answer_start)\n",
    "    end_char = start_char + len(answer_text)\n",
    "    token_indices = [i for i, (s, e) in enumerate(offsets) if not (e <= start_char or s >= end_char)]\n",
    "    if not token_indices:\n",
    "        return None\n",
    "    return token_indices[0], token_indices[-1] + 1\n",
    "\n",
    "\n",
    "def token_level_iou(pred_span: Tuple[int,int], true_span: Tuple[int,int]) -> float:\n",
    "    \"\"\"IoU between two token spans (end exclusive).\"\"\"\n",
    "    ps = set(range(pred_span[0], pred_span[1]))\n",
    "    ts = set(range(true_span[0], true_span[1]))\n",
    "    inter = ps & ts\n",
    "    union = ps | ts\n",
    "    if not union:\n",
    "        return 0.0\n",
    "    return float(len(inter)) / float(len(union))\n",
    "\n",
    "\n",
    "def token_level_iou_from_char_spans(tokenizer, context: str, pred_start: int, pred_text: str, true_start: int, true_text: str) -> float:\n",
    "    p = char_span_to_token_span(tokenizer, context, pred_start, pred_text)\n",
    "    t = char_span_to_token_span(tokenizer, context, true_start, true_text)\n",
    "    if p is None or t is None:\n",
    "        return 0.0\n",
    "    return token_level_iou(p, t)\n",
    "\n",
    "print('Metric utilities loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b1d215",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pipeline' from 'transformers' (C:\\Users\\91983\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mInstalling required packages (transformers, datasets, kagglehub)...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     18\u001b[39m     pip_install([\u001b[33m\"\u001b[39m\u001b[33mtransformers[torch]\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mdatasets\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mkagglehub\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m\"\u001b[39m])  \u001b[38;5;66;03m# torch provided by user environment if available\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'pipeline' from 'transformers' (C:\\Users\\91983\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Setup: install required packages and import\n",
    "import sys, subprocess, os\n",
    "\n",
    "def pip_install(packages):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\"] + packages)\n",
    "\n",
    "# Try imports; install if missing\n",
    "need_install = False\n",
    "try:\n",
    "    import transformers\n",
    "    import datasets\n",
    "    import kagglehub\n",
    "except Exception:\n",
    "    need_install = True\n",
    "\n",
    "if need_install:\n",
    "    print('Installing required packages (transformers, datasets, kagglehub)...')\n",
    "    pip_install([\"transformers[torch]\",\"datasets\",\"kagglehub\",\"tqdm\"])  # torch provided by user environment if available\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "# Initialize a small QA model for speed\n",
    "MODEL_NAME = 'distilbert-base-uncased-distilled-squad'\n",
    "print('Loading model:', MODEL_NAME)\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
    "qa_pipe = pipeline('question-answering', model=qa_model, tokenizer=qa_tokenizer)\n",
    "\n",
    "print('QA pipeline ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b9785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference: download SQuAD (kagglehub) if needed, run QA on the dev set, compute token-level IoU\n",
    "import os\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DATA_DIR = '.'\n",
    "train_file = os.path.join(DATA_DIR, 'train-v1.1.json')\n",
    "dev_file = os.path.join(DATA_DIR, 'dev-v1.1.json')\n",
    "\n",
    "# Try to download via kagglehub if files missing\n",
    "if not (os.path.exists(train_file) and os.path.exists(dev_file)):\n",
    "    try:\n",
    "        import kagglehub\n",
    "        print('Attempting dataset download via kagglehub...')\n",
    "        kagglehub.dataset_download('stanfordu/stanford-question-answering-dataset', path='.', unzip=True)\n",
    "    except Exception as e:\n",
    "        print('kagglehub download failed or not available:', str(e))\n",
    "        print('Please place train-v1.1.json and dev-v1.1.json in the notebook folder and re-run.')\n",
    "\n",
    "# Validate files\n",
    "if not os.path.exists(dev_file):\n",
    "    raise FileNotFoundError('dev-v1.1.json not found in notebook folder')\n",
    "\n",
    "with open(dev_file, 'r', encoding='utf-8') as f:\n",
    "    dev = json.load(f)\n",
    "\n",
    "# Flatten dev examples (context, question, answers[0])\n",
    "examples = []\n",
    "for article in dev['data']:\n",
    "    for para in article['paragraphs']:\n",
    "        context = para['context']\n",
    "        for qa in para['qas']:\n",
    "            qid = qa.get('id')\n",
    "            question = qa['question']\n",
    "            # choose first answer from answers if available (dev has answers)\n",
    "            answers = qa.get('answers', [])\n",
    "            if answers:\n",
    "                true_text = answers[0]['text']\n",
    "                true_start = answers[0]['answer_start']\n",
    "            else:\n",
    "                true_text = ''\n",
    "                true_start = -1\n",
    "            examples.append({'id': qid, 'context': context, 'question': question, 'true_text': true_text, 'true_start': true_start})\n",
    "\n",
    "print('Loaded', len(examples), 'dev examples')\n",
    "\n",
    "# Run QA pipeline and compute token-level IoU\n",
    "results = []\n",
    "for ex in tqdm(examples, total=len(examples)):\n",
    "    try:\n",
    "        qa_res = qa_pipe({'question': ex['question'], 'context': ex['context']})\n",
    "        pred_text = qa_res.get('answer', '')\n",
    "        pred_start = qa_res.get('start', -1)\n",
    "        score = qa_res.get('score', 0.0)\n",
    "    except Exception as e:\n",
    "        pred_text = ''\n",
    "        pred_start = -1\n",
    "        score = 0.0\n",
    "    # compute token IoU using metrics cell utilities\n",
    "    try:\n",
    "        iou = token_level_iou_from_char_spans(qa_tokenizer, ex['context'], pred_start, pred_text, ex['true_start'], ex['true_text'])\n",
    "    except Exception:\n",
    "        iou = 0.0\n",
    "    results.append({'id': ex['id'], 'question': ex['question'], 'pred_text': pred_text, 'pred_start': pred_start, 'score': score, 'true_text': ex['true_text'], 'true_start': ex['true_start'], 'token_iou': iou})\n",
    "\n",
    "# Save results\n",
    "with open('preds.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Also CSV summary\n",
    "import pandas as pd\n",
    "pd.DataFrame(results).to_csv('preds_with_iou.csv', index=False)\n",
    "\n",
    "# Print quick stats\n",
    "import numpy as np\n",
    "ious = [r['token_iou'] for r in results]\n",
    "print('Mean token-level IoU on dev (quick):', np.mean(ious))\n",
    "print('Saved preds.json and preds_with_iou.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51fcc83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
