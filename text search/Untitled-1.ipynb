{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8763a8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fuzzy method: ratio\n",
      "  Best threshold: 50, accuracy: 0.000\n",
      "Evaluating fuzzy method: partial_ratio\n",
      "  Best threshold: 50, accuracy: 0.000\n",
      "Evaluating fuzzy method: token_sort_ratio\n",
      "  Best threshold: 50, accuracy: 0.000\n",
      "Evaluating fuzzy method: token_set_ratio\n",
      "  Best threshold: 50, accuracy: 0.000\n",
      "\n",
      "Best fuzzy method: ratio with threshold 50 acc=0.000\n",
      "\n",
      "Evaluating TF-IDF + cosine similarity...\n",
      "  Best TF-IDF threshold: 0.10, accuracy: 0.950\n",
      "\n",
      "Summary:\n",
      "Fuzzy best method: ratio threshold: 50 accuracy: 0.0\n",
      "TF-IDF best threshold: 0.1 accuracy: 0.95\n",
      "\n",
      "Wrote outputs: new_queries_with_fuzzy_matches.csv, new_queries_with_tfidf_matches.csv, match_comparison_examples.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import fuzz, process\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    # normalize unicode quotes\n",
    "    text = text.replace(\"\\u2019\", \"'\").replace('\"', ' ').replace('\\u201c', ' ').replace('\\u201d', ' ')\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s']+\", ' ', text)\n",
    "    text = re.sub(r\"\\s+\", ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def evaluate_fuzzy(resolved, new, scorer, thresholds=range(50,101)):\n",
    "    # resolved: list of (id, text)\n",
    "    resolved_texts = [t for (_id, t) in resolved]\n",
    "    resolved_ids = [ _id for (_id, t) in resolved]\n",
    "\n",
    "    best = {'threshold': None, 'accuracy': -1, 'preds': None}\n",
    "\n",
    "    # pre-build choices mapping for process.extract\n",
    "    choices = {t: _id for _id, t in resolved}\n",
    "\n",
    "    for thr in thresholds:\n",
    "        preds = []\n",
    "        for q in new['proc_query']:\n",
    "            match = process.extractOne(q, choices, scorer=scorer)\n",
    "            if match is None:\n",
    "                preds.append(None)\n",
    "            else:\n",
    "                matched_text, score, _ = match\n",
    "                if score >= thr:\n",
    "                    preds.append(choices[matched_text])\n",
    "                else:\n",
    "                    preds.append(None)\n",
    "        # compare to ground truth\n",
    "        true = new['Matches_With_Query_ID'].fillna(-1).astype(int).tolist()\n",
    "        pred = [(-1 if p is None else int(p)) for p in preds]\n",
    "        acc = sum(1 for a,b in zip(true, pred) if a==b) / len(true)\n",
    "        if acc > best['accuracy']:\n",
    "            best.update({'threshold': thr, 'accuracy': acc, 'preds': pred})\n",
    "    return best\n",
    "\n",
    "\n",
    "def evaluate_tfidf(resolved, new, thresholds=np.arange(0.1, 1.01, 0.01)):\n",
    "    resolved_texts = [t for (_id, t) in resolved]\n",
    "    resolved_ids = [ _id for (_id, t) in resolved]\n",
    "\n",
    "    vec = TfidfVectorizer().fit(resolved_texts + new['proc_query'].tolist())\n",
    "    R = vec.transform(resolved_texts)\n",
    "    Q = vec.transform(new['proc_query'].tolist())\n",
    "\n",
    "    sims = cosine_similarity(Q, R)\n",
    "\n",
    "    best = {'threshold': None, 'accuracy': -1, 'preds': None}\n",
    "    for thr in thresholds:\n",
    "        preds = []\n",
    "        for i in range(sims.shape[0]):\n",
    "            row = sims[i]\n",
    "            j = row.argmax()\n",
    "            score = row[j]\n",
    "            if score >= thr:\n",
    "                preds.append(resolved_ids[j])\n",
    "            else:\n",
    "                preds.append(None)\n",
    "        true = new['Matches_With_Query_ID'].fillna(-1).astype(int).tolist()\n",
    "        pred = [(-1 if p is None else int(p)) for p in preds]\n",
    "        acc = sum(1 for a,b in zip(true, pred) if a==b) / len(true)\n",
    "        if acc > best['accuracy']:\n",
    "            best.update({'threshold': thr, 'accuracy': acc, 'preds': pred})\n",
    "    return best, sims\n",
    "\n",
    "\n",
    "def main():\n",
    "    resolved_df = pd.read_csv('resolved_queries.csv')\n",
    "    new_df = pd.read_csv('new_queries.csv')\n",
    "\n",
    "    # preprocess texts\n",
    "    resolved_df['proc'] = resolved_df['Pre_Resolved_Query'].apply(preprocess)\n",
    "    new_df['proc_query'] = new_df['Variation_Query'].apply(preprocess)\n",
    "\n",
    "    resolved = list(zip(resolved_df['Query_ID'].astype(str), resolved_df['proc']))\n",
    "\n",
    "    # Evaluate fuzzy methods\n",
    "    methods = {\n",
    "        'ratio': fuzz.ratio,\n",
    "        'partial_ratio': fuzz.partial_ratio,\n",
    "        'token_sort_ratio': fuzz.token_sort_ratio,\n",
    "        'token_set_ratio': fuzz.token_set_ratio\n",
    "    }\n",
    "\n",
    "    fuzzy_results = {}\n",
    "    for name, scorer in methods.items():\n",
    "        print(f\"Evaluating fuzzy method: {name}\")\n",
    "        best = evaluate_fuzzy(resolved, new_df, scorer)\n",
    "        fuzzy_results[name] = best\n",
    "        print(f\"  Best threshold: {best['threshold']}, accuracy: {best['accuracy']:.3f}\")\n",
    "\n",
    "    # pick best fuzzy\n",
    "    best_name = max(fuzzy_results.items(), key=lambda kv: kv[1]['accuracy'])[0]\n",
    "    best_info = fuzzy_results[best_name]\n",
    "    print(f\"\\nBest fuzzy method: {best_name} with threshold {best_info['threshold']} acc={best_info['accuracy']:.3f}\\n\")\n",
    "\n",
    "    # Save fuzzy matches\n",
    "    new_df['fuzzy_pred'] = best_info['preds']\n",
    "    new_df.to_csv('new_queries_with_fuzzy_matches.csv', index=False)\n",
    "\n",
    "    # TF-IDF evaluation\n",
    "    print('Evaluating TF-IDF + cosine similarity...')\n",
    "    tf_best, sims = evaluate_tfidf(resolved, new_df)\n",
    "    print(f\"  Best TF-IDF threshold: {tf_best['threshold']:.2f}, accuracy: {tf_best['accuracy']:.3f}\")\n",
    "\n",
    "    new_df['tfidf_pred'] = tf_best['preds']\n",
    "    # also include best cosine score for each query\n",
    "    best_scores = [sims[i].max() for i in range(sims.shape[0])]\n",
    "    new_df['tfidf_best_score'] = best_scores\n",
    "\n",
    "    new_df.to_csv('new_queries_with_tfidf_matches.csv', index=False)\n",
    "\n",
    "    # Summary\n",
    "    print('\\nSummary:')\n",
    "    print('Fuzzy best method:', best_name, 'threshold:', best_info['threshold'], 'accuracy:', best_info['accuracy'])\n",
    "    print('TF-IDF best threshold:', tf_best['threshold'], 'accuracy:', tf_best['accuracy'])\n",
    "\n",
    "    # show some example matches\n",
    "    out = []\n",
    "    for i, row in new_df.iterrows():\n",
    "        out.append({\n",
    "            'query': row['Variation_Query'],\n",
    "            'ground_truth': row['Matches_With_Query_ID'],\n",
    "            'fuzzy_pred': row['fuzzy_pred'],\n",
    "            'tfidf_pred': row['tfidf_pred'],\n",
    "            'tfidf_score': row['tfidf_best_score']\n",
    "        })\n",
    "    out_df = pd.DataFrame(out)\n",
    "    out_df.to_csv('match_comparison_examples.csv', index=False)\n",
    "    print('\\nWrote outputs: new_queries_with_fuzzy_matches.csv, new_queries_with_tfidf_matches.csv, match_comparison_examples.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56725583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total variants: 101, matched >= 80: 100 (99.01%)\n",
      "\n",
      "Sample matches:\n",
      "           variant_raw        variant_norm matched_base_above_threshold      score best_base_candidate\n",
      "Matches_With_Base_Name matcheswithbasename                         None  59.259259           Base_Name\n",
      "           Thomas King         thomas king                  Thomas King 100.000000         Thomas King\n",
      "           Thomas King         thomas king                  Thomas King 100.000000         Thomas King\n",
      "          Maria Garcia        maria garcia                 Maria Garcia 100.000000        Maria Garcia\n",
      "            Mary Lewis          mary lewis                   Mary Lewis 100.000000          Mary Lewis\n",
      "          Nancy Wright        nancy wright                 Nancy Wright 100.000000        Nancy Wright\n",
      "          Daniel Scott        daniel scott                 Daniel Scott 100.000000        Daniel Scott\n",
      "            John Smith          john smith                   John Smith 100.000000          John Smith\n",
      "         Linda Johnson       linda johnson                Linda Johnson 100.000000       Linda Johnson\n",
      "          Nancy Wright        nancy wright                 Nancy Wright 100.000000        Nancy Wright\n"
     ]
    }
   ],
   "source": [
    "# Fuzzy name matching: read base names and name variations, normalize, and match using RapidFuzz\n",
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "\n",
    "def normalize_name(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s).strip()\n",
    "    # swap \"Last, First\" -> \"First Last\"\n",
    "    if ',' in s:\n",
    "        parts = [p.strip() for p in s.split(',')]\n",
    "        if len(parts) >= 2:\n",
    "            s = parts[1] + ' ' + parts[0]\n",
    "    s = s.lower()\n",
    "    # keep letters and spaces only\n",
    "    s = re.sub(r\"[^a-z\\s]\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Load files (assumes simple one-column CSVs). If your files have headers, adjust accordingly.\n",
    "base = pd.read_csv('base_names.csv', header=None, names=['base_name'])\n",
    "vars_ = pd.read_csv('name_variations.csv', header=None, names=['variant'])\n",
    "\n",
    "base['norm'] = base['base_name'].apply(normalize_name)\n",
    "vars_['norm'] = vars_['variant'].apply(normalize_name)\n",
    "\n",
    "# Build choices list of normalized base names -> original base name (keep first occurrence)\n",
    "choice_map = {}\n",
    "for _, r in base.iterrows():\n",
    "    if r['norm'] not in choice_map and r['norm'] != '':\n",
    "        choice_map[r['norm']] = r['base_name']\n",
    "\n",
    "choices = list(choice_map.keys())\n",
    "\n",
    "results = []\n",
    "THRESHOLD = 80  # adjustable\n",
    "for _, r in vars_.iterrows():\n",
    "    q = r['norm']\n",
    "    if q == '':\n",
    "        results.append((r['variant'], r['norm'], None, 0.0, None))\n",
    "        continue\n",
    "    # try token_set_ratio and token_sort_ratio, choose best\n",
    "    match_ts = process.extractOne(q, choices, scorer=fuzz.token_set_ratio)\n",
    "    match_tsort = process.extractOne(q, choices, scorer=fuzz.token_sort_ratio)\n",
    "\n",
    "    # choose the match with higher score\n",
    "    cand = match_ts if match_ts[1] >= match_tsort[1] else match_tsort\n",
    "    matched_norm, score, _ = cand\n",
    "    matched_base = choice_map.get(matched_norm)\n",
    "    # if below threshold, keep match but note score\n",
    "    matched_base_out = matched_base if score >= THRESHOLD else None\n",
    "    results.append((r['variant'], r['norm'], matched_base_out, float(score), matched_base))\n",
    "\n",
    "out_df = pd.DataFrame(results, columns=['variant_raw','variant_norm','matched_base_above_threshold','score','best_base_candidate'])\n",
    "out_df.to_csv('name_matches.csv', index=False)\n",
    "\n",
    "# Print a short summary and examples\n",
    "num_total = len(out_df)\n",
    "num_matched = out_df['matched_base_above_threshold'].notna().sum()\n",
    "print(f\"Total variants: {num_total}, matched >= {THRESHOLD}: {num_matched} ({num_matched/num_total:.2%})\")\n",
    "print('\\nSample matches:')\n",
    "print(out_df.head(10).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
